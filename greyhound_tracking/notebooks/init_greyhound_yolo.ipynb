{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Object Detection and Annotation with YOLOv8** ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the YOLOv8 model to perform object detection on a video, filter detections to identify greyhounds, and save the annotated video. The code leverages the cv2 library for video processing, ultralytics for YOLOv8, and supervision for object annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import supervision as sv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cv2: OpenCV library for video processing.\n",
    "\n",
    "os: For interacting with the operating system (e.g., checking directories).\n",
    "\n",
    "numpy: For numerical operations.\n",
    "\n",
    "YOLO from ultralytics: YOLOv8 model for object detection.\n",
    "\n",
    "supervision as sv: For object detection and annotation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**File Paths and Model Initialization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREYHOUND_VIDEO = \"../data/raw_videos/20240722NOTG08_V.mp4\"\n",
    "model = YOLO(\"yolov8n.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GREYHOUND_VIDEO: Path to the input video file.\n",
    "\n",
    "model: Initializes the YOLOv8 model with the pre-trained weights yolov8n.pt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Video and Output Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(GREYHOUND_VIDEO)\n",
    "\n",
    "output_dir = \"./output\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "if not os.access(output_dir, os.W_OK):\n",
    "    raise PermissionError(f\"Write permission denied for the directory {output_dir}\")\n",
    "\n",
    "output_path = os.path.join(output_dir, \"object_counting_output_v8_3.mp4\")\n",
    "assert cap.isOpened(), \"Error reading video file\"\n",
    "\n",
    "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
    "\n",
    "fourcc_code = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
    "video_writer = cv2.VideoWriter(output_path, fourcc_code, fps, (w, h))\n",
    "\n",
    "if not video_writer.isOpened():\n",
    "    raise IOError(f\"Error initializing video writer with path {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cap: Opens the input video file.\n",
    "\n",
    "output_dir: Directory to save the output video. Creates the directory if it does not exist.\n",
    "\n",
    "output_path: Path for the output video file.\n",
    "\n",
    "Checks if the video file is opened and initializes VideoWriter with appropriate codec and properties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detection Filtering Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_greyhound_detections(detections):\n",
    "    greyhound_class_id = 16\n",
    "    mask = detections.class_id == greyhound_class_id\n",
    "    filtered_detections = sv.Detections(\n",
    "        xyxy=detections.xyxy[mask],\n",
    "        confidence=detections.confidence[mask],\n",
    "        class_id=detections.class_id[mask]\n",
    "    )\n",
    "    return filtered_detections\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter_greyhound_detections: Custom function to filter detections to only include greyhounds (class ID 16)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Video Processing Loop**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializes BoxAnnotator for annotating bounding boxes.\n",
    "Reads frames from the video file.\n",
    "Performs object detection using YOLOv8.\n",
    "Extracts and filters detections to include only greyhounds.\n",
    "Annotates frames with bounding boxes and writes them to the output video file.\n",
    "Releases video resources and saves the processed video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_annotator = sv.BoxAnnotator(thickness=4)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
    "        break\n",
    "\n",
    "    results = model(frame, imgsz=1280)\n",
    "    boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "    confidences = results[0].boxes.conf.cpu().numpy()\n",
    "    class_ids = results[0].boxes.cls.cpu().numpy().astype(int)\n",
    "\n",
    "    detections = sv.Detections(\n",
    "        xyxy=boxes,\n",
    "        confidence=confidences,\n",
    "        class_id=class_ids\n",
    "    )\n",
    "\n",
    "    greyhound_detections = filter_greyhound_detections(detections)\n",
    "    annotated_frame = box_annotator.annotate(scene=frame, detections=greyhound_detections)\n",
    "    video_writer.write(annotated_frame)\n",
    "\n",
    "cap.release()\n",
    "video_writer.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(f\"Processed video saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script applies YOLOv8 object detection to a video, filters detections to focus on greyhounds, and saves the results to an annotated video file. The setup includes initializing the model, verifying directories, processing frames, and saving the output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
