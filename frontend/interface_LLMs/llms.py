from unsloth import FastLanguageModel
from transformers import pipeline
import torch
import os
from mongo_connector import get_occupancy_by_criteria

if torch.cuda.is_available():
    torch.cuda.empty_cache()
    torch.cuda.ipc_collect()
    
max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!
dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+
load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.

# Load a local model (using GPT-2 here, you can replace with a larger model if needed)
model, tokenizer = FastLanguageModel.from_pretrained(
    model_name = os.getenv("MODEL"), # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B
    max_seq_length = max_seq_length,
    dtype = dtype,
    load_in_4bit = load_in_4bit,
    # token = HF_TOKEN
    )
FastLanguageModel.for_inference(model) 

local_llm = pipeline("text-generation", model=model, tokenizer=tokenizer)


def generate_instruction_response(prompt):
    """
    This module provides functionality to generate responses to given prompts using a pre-trained language model.
    """
    input_ids = tokenizer(prompt, return_tensors="pt").input_ids
    outputs = model.generate(input_ids, max_length=128)
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

def query_occupancy_with_instruction_model(criteria):
    """
    Queries occupancy records based on the given criteria and generates a response using an instruction-tuned model.
    Args:
        criteria (dict): A dictionary containing the criteria to filter occupancy records.
    Returns:
        str: A response generated by the instruction-tuned model based on the occupancy records.
             If no records are found, returns a message indicating no records were found.
    """

    # Get occupancy records based on the given criteria
    records = get_occupancy_by_criteria(criteria)
    
    if records:
        # Create a prompt for the instruction model
        prompt = f"What was the occupancy based on the given criteria?"
        # Generate a response using the instruction-tuned model
        response = generate_instruction_response(prompt + f" The occupancy records are {records}")
        return response
    else:
        return "No records found based on the given criteria."