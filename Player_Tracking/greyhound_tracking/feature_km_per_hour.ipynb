{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWZNEWrH5dcs"
      },
      "source": [
        "## Kilometers per hour Feature\n",
        "Status: ***Completed***\n",
        "\n",
        "### Purpose\n",
        "We aim to improve the current object detection and tracking system by calculating the speed of detected objects (dogs) in kilometers per hour (km/h). This enhancement will allow us to validate the speeds using real-world data, such as GPS information from greyhound racing, which shows an average dog speed of around 62-70 km/h. This real-time speed calculation will add accuracy to the object tracking system and make it easier to verify results.\n",
        "\n",
        "### How?\n",
        "1. **Object Detection:**\n",
        "\n",
        "* We use the Detectron2 library for object detection, specifically utilizing the Mask R-CNN model pre-trained on the COCO dataset to detect dogs. In COCO, dogs are labeled with class ID 17.\n",
        "\n",
        "2. **Object Tracking:**\n",
        "\n",
        "* For tracking, we use the DeepSort tracker to follow detected objects across multiple frames. DeepSort assigns unique IDs to track each object over time.\n",
        "\n",
        "3. **Speed Calculation:**\n",
        "\n",
        "* The speed of each tracked object is calculated by measuring the change in position of the object across frames, using Euclidean distance to find the pixel displacement.\n",
        "* We convert the pixel displacement to meters by using a predefined scale (meters per pixel), then compute the object's speed in meters per second and finally convert it to km/h.\n",
        "\n",
        "### Limitation\n",
        "1. Scale Assumption: We assume a fixed conversion factor for pixels to meters (0.05 meters/pixel in this example). This factor might vary depending on the camera angle, distance, and actual track size. Thus, the calculated speeds may need tuning based on actual GPS data or other real-world measurements.\n",
        "\n",
        "2. Bounding Box Consistency: The size of the bounding box is dynamic and can change with the object's distance from the camera, making speed calculations less reliable when an object moves farther away."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "086047PM5dcu"
      },
      "source": [
        "### Step-by-step Description of the Code:\n",
        "**Installing Dependencies:**\n",
        "\n",
        "The first block installs the Detectron2 library, which provides the tools for object detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_gwkUBNJ8NM",
        "outputId": "040dc34c-8939-4d66-d86a-1c59fbf436f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/facebookresearch/detectron2.git\n",
            "  Cloning https://github.com/facebookresearch/detectron2.git to /tmp/pip-req-build-jn11fztz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/facebookresearch/detectron2.git /tmp/pip-req-build-jn11fztz\n",
            "  Resolved https://github.com/facebookresearch/detectron2.git to commit ebe8b45437f86395352ab13402ba45b75b4d1ddb\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow>=7.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (10.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.7.1)\n",
            "Requirement already satisfied: pycocotools>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.0.8)\n",
            "Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.4.0)\n",
            "Requirement already satisfied: yacs>=0.1.8 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.8)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.9.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (3.0.0)\n",
            "Requirement already satisfied: tqdm>4.29.0 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (4.66.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.15.2)\n",
            "Requirement already satisfied: fvcore<0.1.6,>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.5.post20221221)\n",
            "Requirement already satisfied: iopath<0.1.10,>=0.1.7 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (0.1.9)\n",
            "Requirement already satisfied: omegaconf<2.4,>=2.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (2.3.0)\n",
            "Requirement already satisfied: hydra-core>=1.1 in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (1.3.2)\n",
            "Requirement already satisfied: black in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.8.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from detectron2==0.6) (24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (1.26.4)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from fvcore<0.1.6,>=0.1.5->detectron2==0.6) (6.0.2)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from hydra-core>=1.1->detectron2==0.6) (4.9.3)\n",
            "Requirement already satisfied: portalocker in /usr/local/lib/python3.10/dist-packages (from iopath<0.1.10,>=0.1.7->detectron2==0.6) (2.10.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->detectron2==0.6) (2.9.0.post0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (8.1.7)\n",
            "Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (1.0.0)\n",
            "Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (0.12.1)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.3.2)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (2.0.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from black->detectron2==0.6) (4.12.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.66.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.2.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (2.32.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->detectron2==0.6) (3.0.4)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard->detectron2==0.6) (2024.8.30)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard->detectron2==0.6) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->detectron2==0.6) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->detectron2==0.6) (3.2.2)\n"
          ]
        }
      ],
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7BrKKLx5dcw"
      },
      "source": [
        "**Importing all necessary Libraries**"
      ]
    },
    {
      "source": [
        "!pip install deep_sort_realtime\n",
        "import torch\n",
        "import detectron2\n",
        "import pycocotools\n",
        "import numpy as np\n",
        "import cv2\n",
        "import random\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# import some common detectron2 utilities\n",
        "from detectron2.utils.logger import setup_logger\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.data import MetadataCatalog\n",
        "import os\n",
        "import numpy as np\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort # This should now work as the module has been installed.\n",
        "from scipy.spatial.distance import euclidean"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjIiRMbq6rny",
        "outputId": "e3bc7ebc-1619-49eb-f363-f471a4b72cf1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: deep_sort_realtime in /usr/local/lib/python3.10/dist-packages (1.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (1.26.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (1.13.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from deep_sort_realtime) (4.10.0.84)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hmFAfpoCLkud",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c7d7660-00ba-46fa-e81f-0b1865e7c170"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch:  2.4 ; cuda:  cpu\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Logger detectron2 (DEBUG)>"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
        "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
        "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)\n",
        "\n",
        "setup_logger()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Il7vnClUm7HU"
      },
      "source": [
        "**Model Setup:**\n",
        "\n",
        "* We import the necessary libraries, including Detectron2 for detection, DeepSort for tracking, and cv2 (OpenCV) for video processing.\n",
        "\n",
        "* Next, we configure the Mask R-CNN model from the Detectron2 model zoo. The model is pre-trained on the COCO dataset, and it uses a threshold of 0.5 for detection confidence. The system is set to use CUDA if a GPU is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "rshbe2175dcx"
      },
      "outputs": [],
      "source": [
        "# Define the video path\n",
        "MARKET_SQUARE_VIDEO_PATH = \"/greyhound1.mp4\"\n",
        "\n",
        "# Setup Detectron2 model configuration\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n",
        "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Set threshold for this model\n",
        "cfg.MODEL.DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USoNI2765dcx"
      },
      "source": [
        "**Video Setup:**\n",
        "\n",
        "* The video is loaded using OpenCV’s VideoCapture, and properties such as width, height, and FPS are retrieved to configure the video writer for the output.\n",
        "\n",
        "* We also specify the output directory where the processed video will be saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "K-v3a2xDJvLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c86abe8-5e1b-4b1a-d3a5-4adbbbb25ad7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[09/18 12:10:44 d2.checkpoint.detection_checkpoint]: [DetectionCheckpointer] Loading from https://dl.fbaipublicfiles.com/detectron2/COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x/137849600/model_final_f10217.pkl ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/deep_sort_realtime/embedder/embedder_pytorch.py:53: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  self.model.load_state_dict(torch.load(model_wts_path))\n"
          ]
        }
      ],
      "source": [
        "# Initialize the Detectron2 predictor\n",
        "predictor = DefaultPredictor(cfg)\n",
        "\n",
        "# Initialize the DeepSort tracker\n",
        "tracker = DeepSort(max_age=30)\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(MARKET_SQUARE_VIDEO_PATH)\n",
        "\n",
        "# Verify the output directory and permissions\n",
        "output_dir = \"/content\"\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "if not os.access(output_dir, os.W_OK):\n",
        "    raise PermissionError(f\"Write permission denied for the directory {output_dir}\")\n",
        "\n",
        "# Define the output video path\n",
        "output_path = os.path.join(output_dir, \"dog_tracking_output_kmph.mp4\")\n",
        "\n",
        "assert cap.isOpened(), \"Error reading video file\"\n",
        "\n",
        "# Get video properties\n",
        "w, h, fps = (int(cap.get(x)) for x in (cv2.CAP_PROP_FRAME_WIDTH, cv2.CAP_PROP_FRAME_HEIGHT, cv2.CAP_PROP_FPS))\n",
        "\n",
        "# Initialize VideoWriter with a successful FourCC code\n",
        "fourcc_code = cv2.VideoWriter_fourcc(*\"mp4v\")\n",
        "video_writer = cv2.VideoWriter(output_path, fourcc_code, fps, (w, h))\n",
        "\n",
        "# Example scale: 1 pixel = 0.05 meters (adjust according to your video)\n",
        "scale_meters_per_pixel = 0.05"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7StonVvP5dcy"
      },
      "source": [
        "**Speed Calculation Function:**\n",
        "\n",
        "* This function takes the previous and current positions of an object (in pixels) and calculates the speed in km/h.\n",
        "* First, we calculate the pixel distance between the two positions using Euclidean distance.\n",
        "* Next, we convert the distance in pixels to meters using the defined scale (0.05 meters/pixel).\n",
        "* We then calculate the speed in meters per second by multiplying the distance by the frame rate (FPS) and finally convert it to km/h by multiplying by 3.6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GP0isZ3l5dcy"
      },
      "outputs": [],
      "source": [
        "# Function to calculate speed in km/h\n",
        "def calculate_speed(previous_position, current_position, fps):\n",
        "    distance_pixels = euclidean(previous_position, current_position)\n",
        "    # Convert pixels to meters\n",
        "    distance_meters = distance_pixels * scale_meters_per_pixel\n",
        "    # Speed in meters per second\n",
        "    speed_mps = distance_meters * fps\n",
        "    # Convert to kilometers per hour (km/h)\n",
        "    speed_kmph = speed_mps * 3.6\n",
        "    return speed_kmph\n",
        "\n",
        "# Track previous positions of dogs to calculate speed\n",
        "previous_positions = {}\n",
        "\n",
        "# Process video frames\n",
        "while cap.isOpened():\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        print(\"Video frame is empty or video processing has been successfully completed.\")\n",
        "        break\n",
        "\n",
        "    # Perform object detection\n",
        "    outputs = predictor(frame)\n",
        "\n",
        "    # Extract bounding boxes, confidences, and class IDs\n",
        "    instances = outputs[\"instances\"].to(\"cpu\")\n",
        "    boxes = instances.pred_boxes.tensor.numpy()\n",
        "    confidences = instances.scores.numpy()\n",
        "    class_ids = instances.pred_classes.numpy()\n",
        "\n",
        "    # Filter out only dog detections (Class ID for dogs in COCO dataset is 17)\n",
        "    dog_indices = np.where(class_ids == 17)[0]\n",
        "    boxes = boxes[dog_indices]\n",
        "    confidences = confidences[dog_indices]\n",
        "    class_ids = class_ids[dog_indices]\n",
        "\n",
        "    # Prepare detections for tracking\n",
        "    detections = []\n",
        "    for i in range(len(boxes)):\n",
        "        x1, y1, x2, y2 = boxes[i]\n",
        "        bbox = [x1, y1, x2 - x1, y2 - y1]  # Convert to [x, y, w, h]\n",
        "        detection = (bbox, confidences[i], class_ids[i])\n",
        "        detections.append(detection)\n",
        "\n",
        "    tracked_objects = tracker.update_tracks(detections, frame=frame)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtfwGUBt5dcy"
      },
      "source": [
        "**Processing Each Frame:**\n",
        "\n",
        "1. For each frame in the video:\n",
        "* We first apply Detectron2 to perform object detection. It returns bounding boxes, class IDs, and confidence scores.\n",
        "* We filter out the detections to only keep the ones that belong to the dog class (Class ID 17 in COCO).\n",
        "* The detected bounding boxes are converted into a format suitable for tracking and passed to the DeepSort tracker.\n",
        "2. For each tracked object:\n",
        "* If the object has been detected before (i.e., it has a previous position), we calculate its speed using the calculate_speed function.\n",
        "* We draw the bounding box and label (with the speed in km/h) on the frame."
      ]
    },
    {
      "source": [
        "    labels = []\n",
        "    for obj in tracked_objects:\n",
        "        if not obj.is_confirmed():\n",
        "            continue\n",
        "\n",
        "        box = obj.to_ltwh()  # Get the bounding box as [left, top, width, height]\n",
        "        obj_id = obj.track_id\n",
        "        class_id = obj.det_class\n",
        "\n",
        "        center = (int(box[0] + box[2] / 2), int(box[1] + box[3] / 2))\n",
        "\n",
        "        if obj_id in previous_positions:\n",
        "            speed_kmph = calculate_speed(previous_positions[obj_id], center, fps)\n",
        "            label = f\"ID {obj_id} | Speed: {speed_kmph:.2f} km/h\"\n",
        "        else:\n",
        "            label = f\"ID {obj_id} | Speed: calculating...\"\n",
        "\n",
        "        previous_positions[obj_id] = center\n",
        "\n",
        "        # Draw the box and label on the frame\n",
        "        cv2.rectangle(frame, (int(box[0]), int(box[1])), (int(box[0] + box[2]), int(box[1] + box[3])), (0, 255, 0), 2)\n",
        "        cv2.putText(frame, label, (int(box[0]), int(box[1] - 10)), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
        "\n",
        "    # Write the processed frame to the output video\n",
        "    video_writer.write(frame)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "0Z8M6PhC_JfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueC_zS7F5dcy"
      },
      "source": [
        "**Video Setup:**\n",
        "\n",
        "* The video is loaded using OpenCV’s VideoCapture, and properties such as width, height, and FPS are retrieved to configure the video writer for the output.\n",
        "* We also specify the output directory where the processed video will be saved."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Md_ZBGiR5dcz"
      },
      "source": [
        "**Saving the Video:**\n",
        "\n",
        "After processing all frames, the video is saved to the specified output path."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qtD1d5bW5dcz"
      },
      "outputs": [],
      "source": [
        "cap.release()\n",
        "video_writer.release()\n",
        "# cv2.destroyAllWindows()\n",
        "\n",
        "print(f\"Processed video saved to {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Dj-154pnUWg"
      },
      "source": [
        "**Conclusion**\n",
        "\n",
        "This notebook demonstrates how to detect and track objects (dogs) in a video, calculate their speed in kilometers per hour, and output the result into a new video. The current implementation includes limitations related to the pixel-to-meter scale, and bounding box consistency, but it establishes a baseline for further refinements and validation using GPS data from real-world races.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
