{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GxxfGsClGtN",
        "outputId": "0ebf26ba-8a7c-4522-ca7a-a2e6e3ec9adc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ultralytics\n",
            "  Downloading ultralytics-8.3.126-py3-none-any.whl.metadata (37 kB)\n",
            "Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
            "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
            "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
            "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.2)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
            "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
            "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
            "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
            "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
            "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.4.26)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
            "Downloading ultralytics-8.3.126-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m30.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.126 ultralytics-thop-2.0.14\n"
          ]
        }
      ],
      "source": [
        "!pip install ultralytics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEnSW6ADoIUb",
        "outputId": "8e36cdf1-576b-43a4-eff7-0e5b599992d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CUDA is available!\n",
            "Number of GPUs: 1\n",
            "Current GPU Name: Tesla T4\n",
            "PyTorch CUDA version: 12.4\n",
            "Device variable set to: 'cuda'\n"
          ]
        }
      ],
      "source": [
        "# !pip install torchvision\n",
        "# !pip install --upgrade nvidia-pyindex\n",
        "# !nvidia-smi\n",
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"CUDA is available!\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "    print(f\"Current GPU Name: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"PyTorch CUDA version: {torch.version.cuda}\")\n",
        "else:\n",
        "    print(\"CUDA is NOT available. PyTorch is using CPU.\")\n",
        "\n",
        "# You can also explicitly check the device variable assignment:\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Device variable set to: '{device}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ke-kUTDnBYA",
        "outputId": "b6dad765-73b4-4030-d041-da9fc969c492"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Video FPS: 30.00\n",
            "Desired Annotation FPS: 5\n",
            "Processing every 6 frame(s)\n",
            "Saved frame 90 (Video Frame 534/538)\n",
            "Finished extracting 90 frames to 'extracted_frames'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import os\n",
        "import math\n",
        "\n",
        "# --- Configuration ---\n",
        "VIDEO_PATH = \"/content/race.mp4\"          # Path to your input video\n",
        "OUTPUT_DIR = \"extracted_frames\"  # Directory to save the extracted image frames\n",
        "DESIRED_FPS = 5                  # Annotate approximately 5 frames per second\n",
        "\n",
        "# --- Frame Extraction ---\n",
        "# Create the output directory if it doesn't exist\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "# Open the video file\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: Could not open video file: {VIDEO_PATH}\")\n",
        "    exit()\n",
        "\n",
        "# Get video properties\n",
        "video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "frame_interval = 1 # Default to processing every frame if desired_fps is higher than video_fps or 0\n",
        "if DESIRED_FPS > 0 and DESIRED_FPS < video_fps:\n",
        "     frame_interval = math.ceil(video_fps / DESIRED_FPS) # Calculate how many frames to skip\n",
        "\n",
        "print(f\"Video FPS: {video_fps:.2f}\")\n",
        "print(f\"Desired Annotation FPS: {DESIRED_FPS}\")\n",
        "print(f\"Processing every {frame_interval} frame(s)\")\n",
        "\n",
        "frame_count = 0\n",
        "saved_frame_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # If frame reading was not successful, break the loop\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Check if the current frame should be processed based on the interval\n",
        "    if frame_count % frame_interval == 0:\n",
        "        # Construct the output filename (e.g., frame_00000.jpg)\n",
        "        output_filename = os.path.join(OUTPUT_DIR, f\"frame_{frame_count:05d}.jpg\")\n",
        "        # Save the frame as an image file\n",
        "        cv2.imwrite(output_filename, frame)\n",
        "        saved_frame_count += 1\n",
        "        print(f\"\\rSaved frame {saved_frame_count} (Video Frame {frame_count}/{total_frames})\", end=\"\")\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "# Release the video capture object\n",
        "cap.release()\n",
        "print(f\"\\nFinished extracting {saved_frame_count} frames to '{OUTPUT_DIR}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPdY7xTrnD8p",
        "outputId": "13d30e74-b387-45fd-e08c-422e6545b88c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Using device: cuda\n",
            "Starting auto-annotation on frames in: extracted_frames\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/sam2_b.pt to '/content/sam2_b.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 154M/154M [00:02<00:00, 59.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "image 1/90 /content/extracted_frames/frame_00000.jpg: 384x640 1 person, 55.8ms\n",
            "image 2/90 /content/extracted_frames/frame_00006.jpg: 384x640 1 person, 11.7ms\n",
            "image 3/90 /content/extracted_frames/frame_00012.jpg: 384x640 2 persons, 10.4ms\n",
            "image 4/90 /content/extracted_frames/frame_00018.jpg: 384x640 2 persons, 11.0ms\n",
            "image 5/90 /content/extracted_frames/frame_00024.jpg: 384x640 2 persons, 10.0ms\n",
            "image 6/90 /content/extracted_frames/frame_00030.jpg: 384x640 2 persons, 13.6ms\n",
            "image 7/90 /content/extracted_frames/frame_00036.jpg: 384x640 2 persons, 13.3ms\n",
            "image 8/90 /content/extracted_frames/frame_00042.jpg: 384x640 2 persons, 14.9ms\n",
            "image 9/90 /content/extracted_frames/frame_00048.jpg: 384x640 2 persons, 13.0ms\n",
            "image 10/90 /content/extracted_frames/frame_00054.jpg: 384x640 2 persons, 17.9ms\n",
            "image 11/90 /content/extracted_frames/frame_00060.jpg: 384x640 2 persons, 17.3ms\n",
            "image 12/90 /content/extracted_frames/frame_00066.jpg: 384x640 2 persons, 20.7ms\n",
            "image 13/90 /content/extracted_frames/frame_00072.jpg: 384x640 2 persons, 10.6ms\n",
            "image 14/90 /content/extracted_frames/frame_00078.jpg: 384x640 2 persons, 10.2ms\n",
            "image 15/90 /content/extracted_frames/frame_00084.jpg: 384x640 2 persons, 9.9ms\n",
            "image 16/90 /content/extracted_frames/frame_00090.jpg: 384x640 2 persons, 10.0ms\n",
            "image 17/90 /content/extracted_frames/frame_00096.jpg: 384x640 2 persons, 10.4ms\n",
            "image 18/90 /content/extracted_frames/frame_00102.jpg: 384x640 2 persons, 10.2ms\n",
            "image 19/90 /content/extracted_frames/frame_00108.jpg: 384x640 1 person, 10.0ms\n",
            "image 20/90 /content/extracted_frames/frame_00114.jpg: 384x640 1 person, 11.8ms\n",
            "image 21/90 /content/extracted_frames/frame_00120.jpg: 384x640 1 person, 11.0ms\n",
            "image 22/90 /content/extracted_frames/frame_00126.jpg: 384x640 1 person, 10.9ms\n",
            "image 23/90 /content/extracted_frames/frame_00132.jpg: 384x640 1 person, 15.5ms\n",
            "image 24/90 /content/extracted_frames/frame_00138.jpg: 384x640 1 person, 10.3ms\n",
            "image 25/90 /content/extracted_frames/frame_00144.jpg: 384x640 1 person, 10.7ms\n",
            "image 26/90 /content/extracted_frames/frame_00150.jpg: 384x640 1 person, 9.9ms\n",
            "image 27/90 /content/extracted_frames/frame_00156.jpg: 384x640 1 person, 10.1ms\n",
            "image 28/90 /content/extracted_frames/frame_00162.jpg: 384x640 1 person, 12.4ms\n",
            "image 29/90 /content/extracted_frames/frame_00168.jpg: 384x640 1 person, 9.9ms\n",
            "image 30/90 /content/extracted_frames/frame_00174.jpg: 384x640 1 person, 10.1ms\n",
            "image 31/90 /content/extracted_frames/frame_00180.jpg: 384x640 1 person, 10.7ms\n",
            "image 32/90 /content/extracted_frames/frame_00186.jpg: 384x640 4 persons, 13.4ms\n",
            "image 33/90 /content/extracted_frames/frame_00192.jpg: 384x640 6 persons, 10.9ms\n",
            "image 34/90 /content/extracted_frames/frame_00198.jpg: 384x640 9 persons, 10.5ms\n",
            "image 35/90 /content/extracted_frames/frame_00204.jpg: 384x640 8 persons, 10.3ms\n",
            "image 36/90 /content/extracted_frames/frame_00210.jpg: 384x640 7 persons, 10.0ms\n",
            "image 37/90 /content/extracted_frames/frame_00216.jpg: 384x640 9 persons, 11.6ms\n",
            "image 38/90 /content/extracted_frames/frame_00222.jpg: 384x640 9 persons, 10.3ms\n",
            "image 39/90 /content/extracted_frames/frame_00228.jpg: 384x640 9 persons, 11.3ms\n",
            "image 40/90 /content/extracted_frames/frame_00234.jpg: 384x640 9 persons, 10.6ms\n",
            "image 41/90 /content/extracted_frames/frame_00240.jpg: 384x640 4 persons, 10.4ms\n",
            "image 42/90 /content/extracted_frames/frame_00246.jpg: 384x640 8 persons, 11.0ms\n",
            "image 43/90 /content/extracted_frames/frame_00252.jpg: 384x640 8 persons, 10.3ms\n",
            "image 44/90 /content/extracted_frames/frame_00258.jpg: 384x640 8 persons, 13.7ms\n",
            "image 45/90 /content/extracted_frames/frame_00264.jpg: 384x640 8 persons, 13.6ms\n",
            "image 46/90 /content/extracted_frames/frame_00270.jpg: 384x640 8 persons, 13.1ms\n",
            "image 47/90 /content/extracted_frames/frame_00276.jpg: 384x640 9 persons, 12.8ms\n",
            "image 48/90 /content/extracted_frames/frame_00282.jpg: 384x640 9 persons, 22.9ms\n",
            "image 49/90 /content/extracted_frames/frame_00288.jpg: 384x640 8 persons, 10.5ms\n",
            "image 50/90 /content/extracted_frames/frame_00294.jpg: 384x640 9 persons, 10.2ms\n",
            "image 51/90 /content/extracted_frames/frame_00300.jpg: 384x640 9 persons, 10.4ms\n",
            "image 52/90 /content/extracted_frames/frame_00306.jpg: 384x640 8 persons, 10.6ms\n",
            "image 53/90 /content/extracted_frames/frame_00312.jpg: 384x640 9 persons, 12.9ms\n",
            "image 54/90 /content/extracted_frames/frame_00318.jpg: 384x640 8 persons, 11.6ms\n",
            "image 55/90 /content/extracted_frames/frame_00324.jpg: 384x640 11 persons, 11.6ms\n",
            "image 56/90 /content/extracted_frames/frame_00330.jpg: 384x640 9 persons, 10.8ms\n",
            "image 57/90 /content/extracted_frames/frame_00336.jpg: 384x640 9 persons, 10.8ms\n",
            "image 58/90 /content/extracted_frames/frame_00342.jpg: 384x640 9 persons, 10.2ms\n",
            "image 59/90 /content/extracted_frames/frame_00348.jpg: 384x640 8 persons, 10.5ms\n",
            "image 60/90 /content/extracted_frames/frame_00354.jpg: 384x640 8 persons, 11.2ms\n",
            "image 61/90 /content/extracted_frames/frame_00360.jpg: 384x640 8 persons, 11.5ms\n",
            "image 62/90 /content/extracted_frames/frame_00366.jpg: 384x640 8 persons, 12.4ms\n",
            "image 63/90 /content/extracted_frames/frame_00372.jpg: 384x640 8 persons, 10.9ms\n",
            "image 64/90 /content/extracted_frames/frame_00378.jpg: 384x640 8 persons, 11.1ms\n",
            "image 65/90 /content/extracted_frames/frame_00384.jpg: 384x640 8 persons, 10.6ms\n",
            "image 66/90 /content/extracted_frames/frame_00390.jpg: 384x640 8 persons, 10.1ms\n",
            "image 67/90 /content/extracted_frames/frame_00396.jpg: 384x640 8 persons, 10.7ms\n",
            "image 68/90 /content/extracted_frames/frame_00402.jpg: 384x640 9 persons, 10.1ms\n",
            "image 69/90 /content/extracted_frames/frame_00408.jpg: 384x640 8 persons, 10.4ms\n",
            "image 70/90 /content/extracted_frames/frame_00414.jpg: 384x640 8 persons, 10.7ms\n",
            "image 71/90 /content/extracted_frames/frame_00420.jpg: 384x640 8 persons, 10.7ms\n",
            "image 72/90 /content/extracted_frames/frame_00426.jpg: 384x640 10 persons, 10.7ms\n",
            "image 73/90 /content/extracted_frames/frame_00432.jpg: 384x640 9 persons, 10.7ms\n",
            "image 74/90 /content/extracted_frames/frame_00438.jpg: 384x640 8 persons, 10.5ms\n",
            "image 75/90 /content/extracted_frames/frame_00444.jpg: 384x640 8 persons, 14.0ms\n",
            "image 76/90 /content/extracted_frames/frame_00450.jpg: 384x640 7 persons, 17.6ms\n",
            "image 77/90 /content/extracted_frames/frame_00456.jpg: 384x640 8 persons, 13.9ms\n",
            "image 78/90 /content/extracted_frames/frame_00462.jpg: 384x640 6 persons, 19.4ms\n",
            "image 79/90 /content/extracted_frames/frame_00468.jpg: 384x640 6 persons, 12.9ms\n",
            "image 80/90 /content/extracted_frames/frame_00474.jpg: 384x640 7 persons, 17.2ms\n",
            "image 81/90 /content/extracted_frames/frame_00480.jpg: 384x640 5 persons, 19.3ms\n",
            "image 82/90 /content/extracted_frames/frame_00486.jpg: 384x640 5 persons, 10.2ms\n",
            "image 83/90 /content/extracted_frames/frame_00492.jpg: 384x640 5 persons, 11.8ms\n",
            "image 84/90 /content/extracted_frames/frame_00498.jpg: 384x640 5 persons, 10.6ms\n",
            "image 85/90 /content/extracted_frames/frame_00504.jpg: 384x640 4 persons, 10.1ms\n",
            "image 86/90 /content/extracted_frames/frame_00510.jpg: 384x640 3 persons, 10.3ms\n",
            "image 87/90 /content/extracted_frames/frame_00516.jpg: 384x640 3 persons, 12.2ms\n",
            "image 88/90 /content/extracted_frames/frame_00522.jpg: 384x640 2 persons, 12.4ms\n",
            "image 89/90 /content/extracted_frames/frame_00528.jpg: 384x640 2 persons, 10.5ms\n",
            "image 90/90 /content/extracted_frames/frame_00534.jpg: 384x640 1 person, 10.5ms\n",
            "Speed: 2.7ms preprocess, 12.4ms inference, 6.0ms postprocess per image at shape (1, 3, 384, 640)\n",
            "Annotation process finished. Labels saved in 'output_annotations'\n"
          ]
        }
      ],
      "source": [
        "from ultralytics.data.annotator import auto_annotate\n",
        "import torch # Make sure torch is available for device selection\n",
        "\n",
        "# --- Configuration ---\n",
        "IMAGE_DATA_PATH = \"extracted_frames\" # Path to the directory created in Step 1\n",
        "\n",
        "DET_MODEL_PATH = \"/content/yolo11s-pose.pt\"\n",
        "SAM_MODEL_PATH = \"/content/sam2_b.pt\"\n",
        "OUTPUT_ANN_DIR = \"output_annotations\" # Directory where annotation labels will be saved\n",
        "\n",
        "# Determine device\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Auto Annotation ---\n",
        "print(f\"Starting auto-annotation on frames in: {IMAGE_DATA_PATH}\")\n",
        "auto_annotate(\n",
        "    data=IMAGE_DATA_PATH,\n",
        "    det_model=DET_MODEL_PATH,\n",
        "    sam_model=SAM_MODEL_PATH,\n",
        "    device=device, # Specify the device (GPU is recommended for speed)\n",
        "    output_dir=OUTPUT_ANN_DIR # Specify where the annotations should be saved\n",
        ")\n",
        "print(f\"Annotation process finished. Labels saved in '{OUTPUT_ANN_DIR}'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DUtOJ_cUvoQ3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T7eWmbAPyeo7",
        "outputId": "8b680d88-05c6-43e1-c6ca-2002a508ac37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating dataset directories...\n",
            "Ensured directories exist:\n",
            "  dataset/images/train\n",
            "  dataset/images/val\n",
            "  dataset/labels/train\n",
            "  dataset/labels/val\n",
            "\n",
            "Scanning source image directory: extracted_frames\n",
            "Found 90 images.\n",
            "Splitting data: 72 train (80.0%), 18 validation (20.0%).\n",
            "\n",
            "Copying training files (Images from extracted_frames, Labels from output_annotations)...\n",
            "Attempting to copy 72 files. Source labels expected in: output_annotations\n",
            "Copied 72 training images to dataset/images/train and labels to dataset/labels/train.\n",
            "\n",
            "Copying validation files (Images from extracted_frames, Labels from output_annotations)...\n",
            "Attempting to copy 18 files. Source labels expected in: output_annotations\n",
            "Copied 18 validation images to dataset/images/val and labels to dataset/labels/val.\n",
            "\n",
            "Data organization complete.\n",
            "\n",
            "Creating dataset configuration file: data.yaml\n",
            "Successfully created data.yaml\n",
            "Content:\n",
            "  train: /content/dataset/images/train\n",
            "  val: /content/dataset/images/val\n",
            "  nc: 1\n",
            "  names: ['person']\n",
            "\n",
            "Using device: cuda\n",
            "Loading base model: yolov8s-seg.pt\n",
            "\n",
            "Verifying content of created data.yaml...\n",
            "YAML file content seems consistent with script configuration.\n",
            "\n",
            "Starting model training...\n",
            "Ultralytics 8.3.126 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=data.yaml, degrees=0.0, deterministic=True, device=cuda:0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8s-seg.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=run_auto_yaml_v1, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=custom_yolo_training, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=custom_yolo_training/run_auto_yaml_v1, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=segment, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
            "Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 755k/755k [00:00<00:00, 21.8MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overriding model.yaml nc=80 with nc=1\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       928  ultralytics.nn.modules.conv.Conv             [3, 32, 3, 2]                 \n",
            "  1                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  2                  -1  1     29056  ultralytics.nn.modules.block.C2f             [64, 64, 1, True]             \n",
            "  3                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  4                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  5                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  6                  -1  2    788480  ultralytics.nn.modules.block.C2f             [256, 256, 2, True]           \n",
            "  7                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  8                  -1  1   1838080  ultralytics.nn.modules.block.C2f             [512, 512, 1, True]           \n",
            "  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    591360  ultralytics.nn.modules.block.C2f             [768, 256, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 16                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 19                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1   1969152  ultralytics.nn.modules.block.C2f             [768, 512, 1]                 \n",
            " 22        [15, 18, 21]  1   2770931  ultralytics.nn.modules.head.Segment          [1, 32, 128, [128, 256, 512]] \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "YOLOv8s-seg summary: 151 layers, 11,790,483 parameters, 11,790,467 gradients, 42.7 GFLOPs\n",
            "\n",
            "Transferred 411/417 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 5.35M/5.35M [00:00<00:00, 95.7MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed ✅\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3098.9±701.1 MB/s, size: 379.1 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/dataset/labels/train... 88 images, 2 backgrounds, 0 corrupt: 100%|██████████| 90/90 [00:00<00:00, 581.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/dataset/labels/train.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 1711.7±1119.7 MB/s, size: 360.3 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val... 34 images, 12 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<00:00, 385.14it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/dataset/labels/val.cache\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Plotting labels to custom_yolo_training/run_auto_yaml_v1/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mcustom_yolo_training/run_auto_yaml_v1\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       1/50      4.57G      1.231      1.946      2.973      1.154         72        640: 100%|██████████| 6/6 [00:06<00:00,  1.08s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.664      0.902      0.711      0.586      0.666      0.907      0.714      0.553\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       2/50      4.87G     0.8251      1.297      1.437     0.9136         74        640: 100%|██████████| 6/6 [00:02<00:00,  2.15it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.83it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.494      0.982      0.662      0.548      0.492      0.977      0.657      0.476\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       3/50       4.9G     0.6682      1.006     0.8071     0.8659         65        640: 100%|██████████| 6/6 [00:02<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.447       0.87      0.475      0.363      0.444      0.865      0.474      0.337\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       4/50      4.96G     0.6939      1.016     0.7991     0.8691        103        640: 100%|██████████| 6/6 [00:02<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.70it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.691      0.979      0.741      0.641      0.691      0.979      0.741      0.551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       5/50         5G     0.7003     0.9821     0.7542     0.8638        102        640: 100%|██████████| 6/6 [00:02<00:00,  2.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.44it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.682       0.99      0.746      0.632      0.682       0.99      0.746      0.561\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       6/50      5.04G     0.6804     0.9529     0.7175     0.8661         78        640: 100%|██████████| 6/6 [00:02<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.51it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.652      0.974      0.694      0.594      0.648      0.969       0.69      0.551\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       7/50      5.08G     0.6654      1.009     0.6805     0.8663        118        640: 100%|██████████| 6/6 [00:02<00:00,  2.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.80it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.701      0.969      0.725      0.618      0.699      0.963      0.728      0.567\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       8/50      5.12G     0.6387     0.9631     0.6663     0.8611         85        640: 100%|██████████| 6/6 [00:02<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.644      0.979      0.707      0.608      0.644      0.979      0.703        0.5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "       9/50      5.16G     0.6759      1.016     0.6957     0.8709         98        640: 100%|██████████| 6/6 [00:03<00:00,  1.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.32it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.736      0.954      0.764      0.655      0.736      0.954      0.764      0.584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      10/50       5.2G     0.6534     0.8593      0.657     0.8513         84        640: 100%|██████████| 6/6 [00:02<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.48it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.715      0.897       0.74      0.633      0.715      0.897       0.74      0.548\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      11/50      5.24G     0.6792      0.966     0.6858     0.8717         79        640: 100%|██████████| 6/6 [00:02<00:00,  2.45it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.76it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.723      0.935      0.743      0.643      0.723      0.935      0.739      0.568\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      12/50      5.28G     0.6542     0.8657     0.5835     0.8472         89        640: 100%|██████████| 6/6 [00:02<00:00,  2.19it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.65it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.617      0.881      0.699      0.603      0.617      0.881      0.699      0.562\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      13/50      5.32G     0.6287      0.869     0.6162     0.8577        133        640: 100%|██████████| 6/6 [00:02<00:00,  2.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.649       0.86      0.706      0.602      0.655       0.86      0.705      0.536\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      14/50      5.37G     0.6684     0.8702     0.5893     0.8528         93        640: 100%|██████████| 6/6 [00:02<00:00,  2.64it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.97it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.714      0.886      0.705      0.606      0.714      0.886      0.705      0.565\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      15/50       5.4G     0.5923     0.8066     0.5871     0.8438        103        640: 100%|██████████| 6/6 [00:02<00:00,  2.51it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.73it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.703      0.938      0.723      0.621      0.694      0.929       0.72      0.541\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      16/50      5.44G     0.6566     0.8364     0.5738     0.8552        112        640: 100%|██████████| 6/6 [00:02<00:00,  2.35it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.701      0.969      0.744      0.646      0.697      0.964       0.74      0.605\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      17/50       5.5G     0.5946     0.7936     0.5544     0.8431         86        640: 100%|██████████| 6/6 [00:02<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.08it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.716      0.966      0.764      0.672      0.716      0.966      0.764      0.621\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      18/50      5.54G     0.6079     0.8494      0.586     0.8476         86        640: 100%|██████████| 6/6 [00:02<00:00,  2.63it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.93it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.729      0.948      0.744      0.656      0.733      0.953      0.745      0.595\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      19/50       5.6G     0.6123     0.8353     0.5697     0.8504         93        640: 100%|██████████| 6/6 [00:02<00:00,  2.02it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.02it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.713      0.948      0.742      0.656      0.721      0.943      0.746      0.596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      20/50      5.64G     0.5611     0.7817     0.5516      0.845         98        640: 100%|██████████| 6/6 [00:02<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.722      0.984      0.747      0.657      0.722      0.984      0.747      0.614\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      21/50      5.72G     0.6175     0.8164     0.5171     0.8415         92        640: 100%|██████████| 6/6 [00:02<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.90it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.728       0.99      0.743      0.649      0.728       0.99      0.743      0.588\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      22/50      5.76G     0.5505     0.6681      0.499     0.8383        100        640: 100%|██████████| 6/6 [00:02<00:00,  2.08it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.713      0.979      0.736      0.657      0.713      0.979      0.736      0.617\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      23/50      5.85G     0.5578     0.7125     0.4955     0.8443         82        640: 100%|██████████| 6/6 [00:02<00:00,  2.57it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.647      0.939      0.663      0.586      0.647      0.939      0.665      0.544\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      24/50      5.89G     0.5404      0.724     0.4906     0.8414         73        640: 100%|██████████| 6/6 [00:02<00:00,  2.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193       0.55      0.867      0.561      0.489       0.55      0.867      0.561      0.472\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      25/50      5.95G     0.5835     0.7287     0.4983     0.8387        114        640: 100%|██████████| 6/6 [00:02<00:00,  2.44it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193       0.59      0.912      0.643      0.567       0.59      0.912      0.643      0.527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      26/50      5.99G     0.5412     0.7133     0.5528     0.8438         97        640: 100%|██████████| 6/6 [00:02<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.742      0.974      0.745      0.671      0.742      0.974      0.745      0.623\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      27/50      6.15G     0.5221     0.7171      0.491     0.8208         91        640: 100%|██████████| 6/6 [00:02<00:00,  2.65it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.737      0.969      0.745      0.677      0.737      0.969      0.745      0.628\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      28/50      6.21G     0.5358     0.7162     0.5117     0.8411        107        640: 100%|██████████| 6/6 [00:02<00:00,  2.49it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.19it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.724      0.984      0.774        0.7      0.724      0.984      0.774      0.649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      29/50      6.25G     0.5449     0.7869     0.5462     0.8347         82        640: 100%|██████████| 6/6 [00:02<00:00,  2.22it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.56it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193       0.73       0.99      0.776      0.699       0.73       0.99      0.776      0.648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      30/50      6.39G     0.5155     0.6583     0.4793     0.8217         82        640: 100%|██████████| 6/6 [00:02<00:00,  2.61it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.91it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.722      0.995      0.774      0.709      0.722      0.995      0.774      0.649\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      31/50      6.44G     0.4915     0.6666     0.4916     0.8182        107        640: 100%|██████████| 6/6 [00:02<00:00,  2.58it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.45it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.725      0.999      0.775      0.708      0.725      0.999      0.775      0.674\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      32/50      6.48G     0.5157      0.663      0.481     0.8245         92        640: 100%|██████████| 6/6 [00:03<00:00,  1.92it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.68it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.742      0.956      0.757      0.696      0.742      0.956      0.757      0.641\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      33/50      6.52G     0.4831      0.632     0.4554     0.8298         97        640: 100%|██████████| 6/6 [00:02<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.79it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193       0.74      0.957       0.75      0.688       0.74      0.957       0.75      0.635\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      34/50      6.64G     0.4939     0.6441     0.4398     0.8246        112        640: 100%|██████████| 6/6 [00:02<00:00,  2.55it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.11it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.744      0.963      0.775      0.716      0.744      0.963      0.775      0.672\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      35/50      6.69G     0.4599     0.6545     0.4507     0.8129        122        640: 100%|██████████| 6/6 [00:02<00:00,  2.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.72it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.724      0.993      0.777      0.725      0.724      0.993      0.777      0.666\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      36/50      6.73G     0.4428     0.6051     0.4006     0.8224         64        640: 100%|██████████| 6/6 [00:02<00:00,  2.60it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.69it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.714      0.995      0.749      0.706      0.714      0.995      0.749      0.647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      37/50      6.85G     0.4245     0.6237      0.405     0.8146         88        640: 100%|██████████| 6/6 [00:02<00:00,  2.48it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.05it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.708      0.995      0.744      0.706      0.708      0.995      0.744      0.647\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      38/50      6.96G     0.4491     0.6378     0.4105     0.8241         79        640: 100%|██████████| 6/6 [00:02<00:00,  2.41it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.18it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.728          1      0.766      0.727      0.724      0.994      0.766      0.657\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      39/50         7G     0.4356     0.6367     0.4111     0.8225        101        640: 100%|██████████| 6/6 [00:03<00:00,  1.73it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:01<00:00,  1.66it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.728       0.99      0.764      0.726      0.727      0.981      0.764       0.65\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      40/50      7.04G     0.4212     0.5795     0.4016     0.8111         86        640: 100%|██████████| 6/6 [00:02<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.93it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.731      0.979      0.755       0.72      0.733      0.979      0.755      0.652\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      41/50      7.29G     0.4127     0.6579     0.4095     0.8099         36        640: 100%|██████████| 6/6 [00:05<00:00,  1.05it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.733       0.99      0.755       0.71      0.729      0.984      0.755      0.653\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      42/50      7.33G     0.3839     0.5497     0.3847     0.8034         51        640: 100%|██████████| 6/6 [00:02<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.734      0.972      0.768      0.726      0.753      0.943      0.768      0.648\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      43/50      7.38G     0.4007     0.5708      0.393     0.7915         57        640: 100%|██████████| 6/6 [00:02<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.20it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.733      0.983       0.78      0.733      0.733      0.983       0.78      0.658\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      44/50      5.08G     0.3718     0.5493     0.3815     0.8117         38        640: 100%|██████████| 6/6 [00:02<00:00,  2.50it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.99it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.737      0.974      0.782      0.742      0.733      0.969      0.782      0.667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      45/50      5.33G     0.3632     0.5497     0.3544     0.7923         54        640: 100%|██████████| 6/6 [00:02<00:00,  2.82it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.03it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.737      0.974      0.778      0.743      0.733      0.969      0.777      0.667\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      46/50      5.33G     0.3917     0.5883      0.408     0.7992         55        640: 100%|██████████| 6/6 [00:02<00:00,  2.80it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.36it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.744      0.959      0.806       0.77      0.744      0.959      0.806      0.686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      47/50      5.33G     0.3445     0.5352     0.3535      0.785         54        640: 100%|██████████| 6/6 [00:02<00:00,  2.30it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.744      0.964      0.813      0.773      0.744      0.964      0.813      0.697\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      48/50      5.33G     0.3558     0.5011     0.3656     0.7992         63        640: 100%|██████████| 6/6 [00:02<00:00,  2.83it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.07it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.742      0.964      0.818       0.78      0.742      0.964      0.818        0.7\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      49/50      5.33G     0.3542      0.518     0.3642     0.7889         62        640: 100%|██████████| 6/6 [00:02<00:00,  2.87it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  3.28it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.739      0.969      0.812      0.777      0.739      0.969      0.812      0.692\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "      50/50      5.33G     0.3345      0.494     0.3363     0.7991         53        640: 100%|██████████| 6/6 [00:02<00:00,  2.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.46it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.739      0.983      0.802      0.767      0.739      0.983      0.802      0.686\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "50 epochs completed in 0.057 hours.\n",
            "Optimizer stripped from custom_yolo_training/run_auto_yaml_v1/weights/last.pt, 23.8MB\n",
            "Optimizer stripped from custom_yolo_training/run_auto_yaml_v1/weights/best.pt, 23.8MB\n",
            "\n",
            "Validating custom_yolo_training/run_auto_yaml_v1/weights/best.pt...\n",
            "Ultralytics 8.3.126 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients, 42.4 GFLOPs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 2/2 [00:00<00:00,  2.44it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.742      0.964      0.818       0.78      0.742      0.964      0.818        0.7\n",
            "Speed: 0.1ms preprocess, 4.5ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
            "Results saved to \u001b[1mcustom_yolo_training/run_auto_yaml_v1\u001b[0m\n",
            "Training finished.\n",
            "Results saved in: custom_yolo_training/run_auto_yaml_v1\n",
            "\n",
            "Evaluating model on validation set...\n",
            "Loading best model from: custom_yolo_training/run_auto_yaml_v1/weights/best.pt\n",
            "Ultralytics 8.3.126 🚀 Python-3.11.12 torch-2.6.0+cu124 CUDA:0 (Tesla T4, 15095MiB)\n",
            "YOLOv8s-seg summary (fused): 85 layers, 11,779,987 parameters, 0 gradients, 42.4 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2993.8±1160.1 MB/s, size: 385.0 KB)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/dataset/labels/val.cache... 34 images, 12 backgrounds, 0 corrupt: 100%|██████████| 46/46 [00:00<?, ?it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<00:00,  1.10it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                   all         46        193      0.742      0.964      0.818      0.784      0.742      0.964      0.818      0.695\n",
            "Speed: 4.9ms preprocess, 16.5ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
            "Results saved to \u001b[1mruns/segment/val\u001b[0m\n",
            "Validation Metrics obtained.\n",
            "\n",
            "Script finished.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import glob\n",
        "import random\n",
        "import shutil\n",
        "import yaml # To write and read yaml\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# 1. Source Data Paths\n",
        "SOURCE_IMAGE_DIR = \"extracted_frames\"\n",
        "SOURCE_LABEL_DIR = \"output_annotations\" # Directory containing the .txt label files\n",
        "\n",
        "# 2. Dataset Organization Paths\n",
        "DATASET_BASE_DIR = \"dataset\"\n",
        "TRAIN_IMG_DIR = os.path.join(DATASET_BASE_DIR, \"images\", \"train\")\n",
        "VAL_IMG_DIR = os.path.join(DATASET_BASE_DIR, \"images\", \"val\")\n",
        "TRAIN_LABEL_DIR = os.path.join(DATASET_BASE_DIR, \"labels\", \"train\")\n",
        "VAL_LABEL_DIR = os.path.join(DATASET_BASE_DIR, \"labels\", \"val\")\n",
        "\n",
        "# 3. Train/Validation Split\n",
        "VAL_SPLIT_RATIO = 0.2\n",
        "\n",
        "# 4. data.yaml Configuration\n",
        "# *** IMPORTANT: Define your classes here! ***\n",
        "# Update NUM_CLASSES to the total number of distinct object types you annotated.\n",
        "# Update CLASS_NAMES with the names of your classes in the correct order (index 0, 1, 2...).\n",
        "# Example: If you only annotated 'person' (class 0), use:\n",
        "# NUM_CLASSES = 1\n",
        "# CLASS_NAMES = ['person']\n",
        "# Example: If you annotated 'car' (0) and 'pedestrian' (1), use:\n",
        "# NUM_CLASSES = 2\n",
        "# CLASS_NAMES = ['car', 'pedestrian']\n",
        "NUM_CLASSES = 1 # <<< --- UPDATE THIS\n",
        "CLASS_NAMES = ['person'] # <<< --- UPDATE THIS LIST (Order matters!)\n",
        "\n",
        "# Path where the data.yaml file will be created/used\n",
        "DATA_YAML_PATH = \"data.yaml\"\n",
        "\n",
        "# 5. Model and Training Parameters\n",
        "BASE_MODEL = 'yolov8s-seg.pt' # Adjust if needed (e.g., yolov8s.pt for detection) ot yolo11s-pose.pt\n",
        "EPOCHS = 50\n",
        "IMG_SIZE = 640\n",
        "BATCH_SIZE = 16 # Adjust based on GPU memory\n",
        "PROJECT_NAME = \"custom_yolo_training\"\n",
        "EXPERIMENT_NAME = \"run_auto_yaml_v1\" # Give it a distinct name\n",
        "\n",
        "# --- Helper Function ---\n",
        "def copy_files(file_list, source_img_dir, source_label_dir, dest_img_dir, dest_label_dir):\n",
        "    \"\"\"Copies image and corresponding label files.\"\"\"\n",
        "    copied_count = 0\n",
        "    label_missing_count = 0\n",
        "    print(f\"Attempting to copy {len(file_list)} files. Source labels expected in: {source_label_dir}\")\n",
        "    for img_filename in file_list:\n",
        "        base_name = os.path.splitext(img_filename)[0]\n",
        "        label_filename = f\"{base_name}.txt\"\n",
        "        src_img_path = os.path.join(source_img_dir, img_filename)\n",
        "        src_label_path = os.path.join(source_label_dir, label_filename)\n",
        "        dest_img_path = os.path.join(dest_img_dir, img_filename)\n",
        "        dest_label_path = os.path.join(dest_label_dir, label_filename)\n",
        "\n",
        "        if os.path.exists(src_img_path):\n",
        "            shutil.copy2(src_img_path, dest_img_path)\n",
        "            copied_count += 1\n",
        "            if os.path.exists(src_label_path):\n",
        "                shutil.copy2(src_label_path, dest_label_path)\n",
        "            else:\n",
        "                label_missing_count += 1\n",
        "                print(f\"Warning: Label file not found for image {img_filename} at {src_label_path}. Image copied without label.\")\n",
        "        else:\n",
        "            print(f\"Warning: Source image not found during copy: {src_img_path}\")\n",
        "            continue\n",
        "    return copied_count, label_missing_count\n",
        "\n",
        "# --- 1. Setup Directories ---\n",
        "print(\"Creating dataset directories...\")\n",
        "os.makedirs(TRAIN_IMG_DIR, exist_ok=True)\n",
        "os.makedirs(VAL_IMG_DIR, exist_ok=True)\n",
        "os.makedirs(TRAIN_LABEL_DIR, exist_ok=True)\n",
        "os.makedirs(VAL_LABEL_DIR, exist_ok=True)\n",
        "print(f\"Ensured directories exist:\\n  {TRAIN_IMG_DIR}\\n  {VAL_IMG_DIR}\\n  {TRAIN_LABEL_DIR}\\n  {VAL_LABEL_DIR}\")\n",
        "\n",
        "# --- 2. Prepare File List and Split ---\n",
        "print(f\"\\nScanning source image directory: {SOURCE_IMAGE_DIR}\")\n",
        "if not os.path.isdir(SOURCE_IMAGE_DIR):\n",
        "    print(f\"Error: Source image directory not found at '{SOURCE_IMAGE_DIR}'\")\n",
        "    exit()\n",
        "if not os.path.isdir(SOURCE_LABEL_DIR):\n",
        "    print(f\"Error: Source label directory not found at '{SOURCE_LABEL_DIR}'\")\n",
        "    exit()\n",
        "\n",
        "image_extensions = [\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\", \"*.gif\", \"*.webp\"]\n",
        "all_image_files = []\n",
        "for ext in image_extensions:\n",
        "    all_image_files.extend(glob.glob(os.path.join(SOURCE_IMAGE_DIR, ext)))\n",
        "\n",
        "all_image_filenames = [os.path.basename(f) for f in all_image_files]\n",
        "total_images = len(all_image_filenames)\n",
        "\n",
        "if total_images == 0:\n",
        "    print(f\"Error: No image files found in {SOURCE_IMAGE_DIR} with extensions {image_extensions}\")\n",
        "    exit()\n",
        "\n",
        "print(f\"Found {total_images} images.\")\n",
        "random.shuffle(all_image_filenames)\n",
        "split_index = int(total_images * (1 - VAL_SPLIT_RATIO))\n",
        "train_filenames = all_image_filenames[:split_index]\n",
        "val_filenames = all_image_filenames[split_index:]\n",
        "print(f\"Splitting data: {len(train_filenames)} train ({100*(1-VAL_SPLIT_RATIO):.1f}%), {len(val_filenames)} validation ({100*VAL_SPLIT_RATIO:.1f}%).\")\n",
        "\n",
        "# --- 3. Copy Files to Structured Directories ---\n",
        "print(f\"\\nCopying training files (Images from {SOURCE_IMAGE_DIR}, Labels from {SOURCE_LABEL_DIR})...\")\n",
        "train_copied, train_labels_missing = copy_files(train_filenames, SOURCE_IMAGE_DIR, SOURCE_LABEL_DIR, TRAIN_IMG_DIR, TRAIN_LABEL_DIR)\n",
        "print(f\"Copied {train_copied} training images to {TRAIN_IMG_DIR} and labels to {TRAIN_LABEL_DIR}.\")\n",
        "if train_labels_missing > 0:\n",
        "    print(f\"Warning: {train_labels_missing} training label files were missing from {SOURCE_LABEL_DIR}.\")\n",
        "\n",
        "print(f\"\\nCopying validation files (Images from {SOURCE_IMAGE_DIR}, Labels from {SOURCE_LABEL_DIR})...\")\n",
        "val_copied, val_labels_missing = copy_files(val_filenames, SOURCE_IMAGE_DIR, SOURCE_LABEL_DIR, VAL_IMG_DIR, VAL_LABEL_DIR)\n",
        "print(f\"Copied {val_copied} validation images to {VAL_IMG_DIR} and labels to {VAL_LABEL_DIR}.\")\n",
        "if val_labels_missing > 0:\n",
        "    print(f\"Warning: {val_labels_missing} validation label files were missing from {SOURCE_LABEL_DIR}.\")\n",
        "\n",
        "print(\"\\nData organization complete.\")\n",
        "\n",
        "# --- 4. Create data.yaml File ---\n",
        "print(f\"\\nCreating dataset configuration file: {DATA_YAML_PATH}\")\n",
        "\n",
        "# Use absolute paths for robustness in the YAML file\n",
        "# This ensures YOLO can find the data regardless of where the script is run from\n",
        "abs_train_img_dir = os.path.abspath(TRAIN_IMG_DIR)\n",
        "abs_val_img_dir = os.path.abspath(VAL_IMG_DIR)\n",
        "\n",
        "# Create the dictionary structure for the YAML data\n",
        "data_yaml_content = {\n",
        "    'train': abs_train_img_dir,\n",
        "    'val': abs_val_img_dir,\n",
        "    'nc': NUM_CLASSES,\n",
        "    'names': CLASS_NAMES\n",
        "}\n",
        "\n",
        "# Write the dictionary to the YAML file\n",
        "try:\n",
        "    with open(DATA_YAML_PATH, 'w') as f:\n",
        "        yaml.dump(data_yaml_content, f, default_flow_style=None, sort_keys=False)\n",
        "    print(f\"Successfully created {DATA_YAML_PATH}\")\n",
        "    print(\"Content:\")\n",
        "    print(f\"  train: {abs_train_img_dir}\")\n",
        "    print(f\"  val: {abs_val_img_dir}\")\n",
        "    print(f\"  nc: {NUM_CLASSES}\")\n",
        "    print(f\"  names: {CLASS_NAMES}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating {DATA_YAML_PATH}: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- 5. Device Setup ---\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "# --- 6. Load Base Model ---\n",
        "print(f\"Loading base model: {BASE_MODEL}\")\n",
        "if not os.path.exists(BASE_MODEL):\n",
        "    print(f\"Info: Base model '{BASE_MODEL}' not found locally. YOLO will attempt to download it.\")\n",
        "model = YOLO(BASE_MODEL)\n",
        "\n",
        "# --- 7. Verify data.yaml (Optional check after creation) ---\n",
        "print(f\"\\nVerifying content of created {DATA_YAML_PATH}...\")\n",
        "try:\n",
        "    with open(DATA_YAML_PATH, 'r') as f:\n",
        "        data_config = yaml.safe_load(f)\n",
        "        if data_config['nc'] != NUM_CLASSES or data_config['names'] != CLASS_NAMES:\n",
        "             print(f\"Warning: Mismatch between config variables and {DATA_YAML_PATH} content.\")\n",
        "        else:\n",
        "             print(f\"YAML file content seems consistent with script configuration.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error reading back {DATA_YAML_PATH} for verification: {e}\")\n",
        "    # Decide if you want to exit or continue if verification fails\n",
        "    # exit()\n",
        "\n",
        "# --- 8. Start Training ---\n",
        "print(\"\\nStarting model training...\")\n",
        "try:\n",
        "    results = model.train(\n",
        "        data=DATA_YAML_PATH,      # Path to the data configuration file\n",
        "        epochs=EPOCHS,            # Number of training epochs\n",
        "        imgsz=IMG_SIZE,           # Input image size\n",
        "        batch=BATCH_SIZE,         # Number of images per batch\n",
        "        device=device,            # Device to run on ('cuda' or 'cpu')\n",
        "        project=PROJECT_NAME,     # Directory to save results\n",
        "        name=EXPERIMENT_NAME,     # Subdirectory name for this specific run\n",
        "        exist_ok=False            # Prevent overwriting existing runs\n",
        "    )\n",
        "    print(\"Training finished.\")\n",
        "    print(f\"Results saved in: {results.save_dir}\")\n",
        "\n",
        "    # --- 9. Post-Training Evaluation (Optional) ---\n",
        "    print(\"\\nEvaluating model on validation set...\")\n",
        "    best_model_path = os.path.join(results.save_dir, 'weights', 'best.pt')\n",
        "    if os.path.exists(best_model_path):\n",
        "        print(f\"Loading best model from: {best_model_path}\")\n",
        "        best_model = YOLO(best_model_path)\n",
        "        metrics = best_model.val()\n",
        "        print(\"Validation Metrics obtained.\")\n",
        "        # Inspect metrics object for results (e.g., metrics.box.map50_95)\n",
        "    else:\n",
        "        print(f\"Warning: Could not find best model weights at {best_model_path}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\nAn error occurred during training or evaluation: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "\n",
        "print(\"\\nScript finished.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2FstyhHt0iG0",
        "outputId": "091526dc-0496-44da-88cb-6c64742e7b1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading model from: /content/custom_yolo_training/run_auto_yaml_v1/weights/best.pt\n",
            "Model loaded successfully on device: cuda\n",
            "Opening input video: /content/race.mp4\n",
            "Video properties: 1920x1080 @ 30.00 FPS, 538 frames\n",
            "Output video will be saved to: output_video.mp4\n",
            "Processing frame 1/538...\n",
            "Processing frame 2/538...\n",
            "Processing frame 3/538...\n",
            "Processing frame 4/538...\n",
            "Processing frame 5/538...\n",
            "Processing frame 6/538...\n",
            "Processing frame 7/538...\n",
            "Processing frame 8/538...\n",
            "Processing frame 9/538...\n",
            "Processing frame 10/538...\n",
            "Processing frame 11/538...\n",
            "Processing frame 12/538...\n",
            "Processing frame 13/538...\n",
            "Processing frame 14/538...\n",
            "Processing frame 15/538...\n",
            "Processing frame 16/538...\n",
            "Processing frame 17/538...\n",
            "Processing frame 18/538...\n",
            "Processing frame 19/538...\n",
            "Processing frame 20/538...\n",
            "Processing frame 21/538...\n",
            "Processing frame 22/538...\n",
            "Processing frame 23/538...\n",
            "Processing frame 24/538...\n",
            "Processing frame 25/538...\n",
            "Processing frame 26/538...\n",
            "Processing frame 27/538...\n",
            "Processing frame 28/538...\n",
            "Processing frame 29/538...\n",
            "Processing frame 30/538...\n",
            "Processing frame 31/538...\n",
            "Processing frame 32/538...\n",
            "Processing frame 33/538...\n",
            "Processing frame 34/538...\n",
            "Processing frame 35/538...\n",
            "Processing frame 36/538...\n",
            "Processing frame 37/538...\n",
            "Processing frame 38/538...\n",
            "Processing frame 39/538...\n",
            "Processing frame 40/538...\n",
            "Processing frame 41/538...\n",
            "Processing frame 42/538...\n",
            "Processing frame 43/538...\n",
            "Processing frame 44/538...\n",
            "Processing frame 45/538...\n",
            "Processing frame 46/538...\n",
            "Processing frame 47/538...\n",
            "Processing frame 48/538...\n",
            "Processing frame 49/538...\n",
            "Processing frame 50/538...\n",
            "Processing frame 51/538...\n",
            "Processing frame 52/538...\n",
            "Processing frame 53/538...\n",
            "Processing frame 54/538...\n",
            "Processing frame 55/538...\n",
            "Processing frame 56/538...\n",
            "Processing frame 57/538...\n",
            "Processing frame 58/538...\n",
            "Processing frame 59/538...\n",
            "Processing frame 60/538...\n",
            "Processing frame 61/538...\n",
            "Processing frame 62/538...\n",
            "Processing frame 63/538...\n",
            "Processing frame 64/538...\n",
            "Processing frame 65/538...\n",
            "Processing frame 66/538...\n",
            "Processing frame 67/538...\n",
            "Processing frame 68/538...\n",
            "Processing frame 69/538...\n",
            "Processing frame 70/538...\n",
            "Processing frame 71/538...\n",
            "Processing frame 72/538...\n",
            "Processing frame 73/538...\n",
            "Processing frame 74/538...\n",
            "Processing frame 75/538...\n",
            "Processing frame 76/538...\n",
            "Processing frame 77/538...\n",
            "Processing frame 78/538...\n",
            "Processing frame 79/538...\n",
            "Processing frame 80/538...\n",
            "Processing frame 81/538...\n",
            "Processing frame 82/538...\n",
            "Processing frame 83/538...\n",
            "Processing frame 84/538...\n",
            "Processing frame 85/538...\n",
            "Processing frame 86/538...\n",
            "Processing frame 87/538...\n",
            "Processing frame 88/538...\n",
            "Processing frame 89/538...\n",
            "Processing frame 90/538...\n",
            "Processing frame 91/538...\n",
            "Processing frame 92/538...\n",
            "Processing frame 93/538...\n",
            "Processing frame 94/538...\n",
            "Processing frame 95/538...\n",
            "Processing frame 96/538...\n",
            "Processing frame 97/538...\n",
            "Processing frame 98/538...\n",
            "Processing frame 99/538...\n",
            "Processing frame 100/538...\n",
            "Processing frame 101/538...\n",
            "Processing frame 102/538...\n",
            "Processing frame 103/538...\n",
            "Processing frame 104/538...\n",
            "Processing frame 105/538...\n",
            "Processing frame 106/538...\n",
            "Processing frame 107/538...\n",
            "Processing frame 108/538...\n",
            "Processing frame 109/538...\n",
            "Processing frame 110/538...\n",
            "Processing frame 111/538...\n",
            "Processing frame 112/538...\n",
            "Processing frame 113/538...\n",
            "Processing frame 114/538...\n",
            "Processing frame 115/538...\n",
            "Processing frame 116/538...\n",
            "Processing frame 117/538...\n",
            "Processing frame 118/538...\n",
            "Processing frame 119/538...\n",
            "Processing frame 120/538...\n",
            "Processing frame 121/538...\n",
            "Processing frame 122/538...\n",
            "Processing frame 123/538...\n",
            "Processing frame 124/538...\n",
            "Processing frame 125/538...\n",
            "Processing frame 126/538...\n",
            "Processing frame 127/538...\n",
            "Processing frame 128/538...\n",
            "Processing frame 129/538...\n",
            "Processing frame 130/538...\n",
            "Processing frame 131/538...\n",
            "Processing frame 132/538...\n",
            "Processing frame 133/538...\n",
            "Processing frame 134/538...\n",
            "Processing frame 135/538...\n",
            "Processing frame 136/538...\n",
            "Processing frame 137/538...\n",
            "Processing frame 138/538...\n",
            "Processing frame 139/538...\n",
            "Processing frame 140/538...\n",
            "Processing frame 141/538...\n",
            "Processing frame 142/538...\n",
            "Processing frame 143/538...\n",
            "Processing frame 144/538...\n",
            "Processing frame 145/538...\n",
            "Processing frame 146/538...\n",
            "Processing frame 147/538...\n",
            "Processing frame 148/538...\n",
            "Processing frame 149/538...\n",
            "Processing frame 150/538...\n",
            "Processing frame 151/538...\n",
            "Processing frame 152/538...\n",
            "Processing frame 153/538...\n",
            "Processing frame 154/538...\n",
            "Processing frame 155/538...\n",
            "Processing frame 156/538...\n",
            "Processing frame 157/538...\n",
            "Processing frame 158/538...\n",
            "Processing frame 159/538...\n",
            "Processing frame 160/538...\n",
            "Processing frame 161/538...\n",
            "Processing frame 162/538...\n",
            "Processing frame 163/538...\n",
            "Processing frame 164/538...\n",
            "Processing frame 165/538...\n",
            "Processing frame 166/538...\n",
            "Processing frame 167/538...\n",
            "Processing frame 168/538...\n",
            "Processing frame 169/538...\n",
            "Processing frame 170/538...\n",
            "Processing frame 171/538...\n",
            "Processing frame 172/538...\n",
            "Processing frame 173/538...\n",
            "Processing frame 174/538...\n",
            "Processing frame 175/538...\n",
            "Processing frame 176/538...\n",
            "Processing frame 177/538...\n",
            "Processing frame 178/538...\n",
            "Processing frame 179/538...\n",
            "Processing frame 180/538...\n",
            "Processing frame 181/538...\n",
            "Processing frame 182/538...\n",
            "Processing frame 183/538...\n",
            "Processing frame 184/538...\n",
            "Processing frame 185/538...\n",
            "Processing frame 186/538...\n",
            "Processing frame 187/538...\n",
            "Processing frame 188/538...\n",
            "Processing frame 189/538...\n",
            "Processing frame 190/538...\n",
            "Processing frame 191/538...\n",
            "Processing frame 192/538...\n",
            "Processing frame 193/538...\n",
            "Processing frame 194/538...\n",
            "Processing frame 195/538...\n",
            "Processing frame 196/538...\n",
            "Processing frame 197/538...\n",
            "Processing frame 198/538...\n",
            "Processing frame 199/538...\n",
            "Processing frame 200/538...\n",
            "Processing frame 201/538...\n",
            "Processing frame 202/538...\n",
            "Processing frame 203/538...\n",
            "Processing frame 204/538...\n",
            "Processing frame 205/538...\n",
            "Processing frame 206/538...\n",
            "Processing frame 207/538...\n",
            "Processing frame 208/538...\n",
            "Processing frame 209/538...\n",
            "Processing frame 210/538...\n",
            "Processing frame 211/538...\n",
            "Processing frame 212/538...\n",
            "Processing frame 213/538...\n",
            "Processing frame 214/538...\n",
            "Processing frame 215/538...\n",
            "Processing frame 216/538...\n",
            "Processing frame 217/538...\n",
            "Processing frame 218/538...\n",
            "Processing frame 219/538...\n",
            "Processing frame 220/538...\n",
            "Processing frame 221/538...\n",
            "Processing frame 222/538...\n",
            "Processing frame 223/538...\n",
            "Processing frame 224/538...\n",
            "Processing frame 225/538...\n",
            "Processing frame 226/538...\n",
            "Processing frame 227/538...\n",
            "Processing frame 228/538...\n",
            "Processing frame 229/538...\n",
            "Processing frame 230/538...\n",
            "Processing frame 231/538...\n",
            "Processing frame 232/538...\n",
            "Processing frame 233/538...\n",
            "Processing frame 234/538...\n",
            "Processing frame 235/538...\n",
            "Processing frame 236/538...\n",
            "Processing frame 237/538...\n",
            "Processing frame 238/538...\n",
            "Processing frame 239/538...\n",
            "Processing frame 240/538...\n",
            "Processing frame 241/538...\n",
            "Processing frame 242/538...\n",
            "Processing frame 243/538...\n",
            "Processing frame 244/538...\n",
            "Processing frame 245/538...\n",
            "Processing frame 246/538...\n",
            "Processing frame 247/538...\n",
            "Processing frame 248/538...\n",
            "Processing frame 249/538...\n",
            "Processing frame 250/538...\n",
            "Processing frame 251/538...\n",
            "Processing frame 252/538...\n",
            "Processing frame 253/538...\n",
            "Processing frame 254/538...\n",
            "Processing frame 255/538...\n",
            "Processing frame 256/538...\n",
            "Processing frame 257/538...\n",
            "Processing frame 258/538...\n",
            "Processing frame 259/538...\n",
            "Processing frame 260/538...\n",
            "Processing frame 261/538...\n",
            "Processing frame 262/538...\n",
            "Processing frame 263/538...\n",
            "Processing frame 264/538...\n",
            "Processing frame 265/538...\n",
            "Processing frame 266/538...\n",
            "Processing frame 267/538...\n",
            "Processing frame 268/538...\n",
            "Processing frame 269/538...\n",
            "Processing frame 270/538...\n",
            "Processing frame 271/538...\n",
            "Processing frame 272/538...\n",
            "Processing frame 273/538...\n",
            "Processing frame 274/538...\n",
            "Processing frame 275/538...\n",
            "Processing frame 276/538...\n",
            "Processing frame 277/538...\n",
            "Processing frame 278/538...\n",
            "Processing frame 279/538...\n",
            "Processing frame 280/538...\n",
            "Processing frame 281/538...\n",
            "Processing frame 282/538...\n",
            "Processing frame 283/538...\n",
            "Processing frame 284/538...\n",
            "Processing frame 285/538...\n",
            "Processing frame 286/538...\n",
            "Processing frame 287/538...\n",
            "Processing frame 288/538...\n",
            "Processing frame 289/538...\n",
            "Processing frame 290/538...\n",
            "Processing frame 291/538...\n",
            "Processing frame 292/538...\n",
            "Processing frame 293/538...\n",
            "Processing frame 294/538...\n",
            "Processing frame 295/538...\n",
            "Processing frame 296/538...\n",
            "Processing frame 297/538...\n",
            "Processing frame 298/538...\n",
            "Processing frame 299/538...\n",
            "Processing frame 300/538...\n",
            "Processing frame 301/538...\n",
            "Processing frame 302/538...\n",
            "Processing frame 303/538...\n",
            "Processing frame 304/538...\n",
            "Processing frame 305/538...\n",
            "Processing frame 306/538...\n",
            "Processing frame 307/538...\n",
            "Processing frame 308/538...\n",
            "Processing frame 309/538...\n",
            "Processing frame 310/538...\n",
            "Processing frame 311/538...\n",
            "Processing frame 312/538...\n",
            "Processing frame 313/538...\n",
            "Processing frame 314/538...\n",
            "Processing frame 315/538...\n",
            "Processing frame 316/538...\n",
            "Processing frame 317/538...\n",
            "Processing frame 318/538...\n",
            "Processing frame 319/538...\n",
            "Processing frame 320/538...\n",
            "Processing frame 321/538...\n",
            "Processing frame 322/538...\n",
            "Processing frame 323/538...\n",
            "Processing frame 324/538...\n",
            "Processing frame 325/538...\n",
            "Processing frame 326/538...\n",
            "Processing frame 327/538...\n",
            "Processing frame 328/538...\n",
            "Processing frame 329/538...\n",
            "Processing frame 330/538...\n",
            "Processing frame 331/538...\n",
            "Processing frame 332/538...\n",
            "Processing frame 333/538...\n",
            "Processing frame 334/538...\n",
            "Processing frame 335/538...\n",
            "Processing frame 336/538...\n",
            "Processing frame 337/538...\n",
            "Processing frame 338/538...\n",
            "Processing frame 339/538...\n",
            "Processing frame 340/538...\n",
            "Processing frame 341/538...\n",
            "Processing frame 342/538...\n",
            "Processing frame 343/538...\n",
            "Processing frame 344/538...\n",
            "Processing frame 345/538...\n",
            "Processing frame 346/538...\n",
            "Processing frame 347/538...\n",
            "Processing frame 348/538...\n",
            "Processing frame 349/538...\n",
            "Processing frame 350/538...\n",
            "Processing frame 351/538...\n",
            "Processing frame 352/538...\n",
            "Processing frame 353/538...\n",
            "Processing frame 354/538...\n",
            "Processing frame 355/538...\n",
            "Processing frame 356/538...\n",
            "Processing frame 357/538...\n",
            "Processing frame 358/538...\n",
            "Processing frame 359/538...\n",
            "Processing frame 360/538...\n",
            "Processing frame 361/538...\n",
            "Processing frame 362/538...\n",
            "Processing frame 363/538...\n",
            "Processing frame 364/538...\n",
            "Processing frame 365/538...\n",
            "Processing frame 366/538...\n",
            "Processing frame 367/538...\n",
            "Processing frame 368/538...\n",
            "Processing frame 369/538...\n",
            "Processing frame 370/538...\n",
            "Processing frame 371/538...\n",
            "Processing frame 372/538...\n",
            "Processing frame 373/538...\n",
            "Processing frame 374/538...\n",
            "Processing frame 375/538...\n",
            "Processing frame 376/538...\n",
            "Processing frame 377/538...\n",
            "Processing frame 378/538...\n",
            "Processing frame 379/538...\n",
            "Processing frame 380/538...\n",
            "Processing frame 381/538...\n",
            "Processing frame 382/538...\n",
            "Processing frame 383/538...\n",
            "Processing frame 384/538...\n",
            "Processing frame 385/538...\n",
            "Processing frame 386/538...\n",
            "Processing frame 387/538...\n",
            "Processing frame 388/538...\n",
            "Processing frame 389/538...\n",
            "Processing frame 390/538...\n",
            "Processing frame 391/538...\n",
            "Processing frame 392/538...\n",
            "Processing frame 393/538...\n",
            "Processing frame 394/538...\n",
            "Processing frame 395/538...\n",
            "Processing frame 396/538...\n",
            "Processing frame 397/538...\n",
            "Processing frame 398/538...\n",
            "Processing frame 399/538...\n",
            "Processing frame 400/538...\n",
            "Processing frame 401/538...\n",
            "Processing frame 402/538...\n",
            "Processing frame 403/538...\n",
            "Processing frame 404/538...\n",
            "Processing frame 405/538...\n",
            "Processing frame 406/538...\n",
            "Processing frame 407/538...\n",
            "Processing frame 408/538...\n",
            "Processing frame 409/538...\n",
            "Processing frame 410/538...\n",
            "Processing frame 411/538...\n",
            "Processing frame 412/538...\n",
            "Processing frame 413/538...\n",
            "Processing frame 414/538...\n",
            "Processing frame 415/538...\n",
            "Processing frame 416/538...\n",
            "Processing frame 417/538...\n",
            "Processing frame 418/538...\n",
            "Processing frame 419/538...\n",
            "Processing frame 420/538...\n",
            "Processing frame 421/538...\n",
            "Processing frame 422/538...\n",
            "Processing frame 423/538...\n",
            "Processing frame 424/538...\n",
            "Processing frame 425/538...\n",
            "Processing frame 426/538...\n",
            "Processing frame 427/538...\n",
            "Processing frame 428/538...\n",
            "Processing frame 429/538...\n",
            "Processing frame 430/538...\n",
            "Processing frame 431/538...\n",
            "Processing frame 432/538...\n",
            "Processing frame 433/538...\n",
            "Processing frame 434/538...\n",
            "Processing frame 435/538...\n",
            "Processing frame 436/538...\n",
            "Processing frame 437/538...\n",
            "Processing frame 438/538...\n",
            "Processing frame 439/538...\n",
            "Processing frame 440/538...\n",
            "Processing frame 441/538...\n",
            "Processing frame 442/538...\n",
            "Processing frame 443/538...\n",
            "Processing frame 444/538...\n",
            "Processing frame 445/538...\n",
            "Processing frame 446/538...\n",
            "Processing frame 447/538...\n",
            "Processing frame 448/538...\n",
            "Processing frame 449/538...\n",
            "Processing frame 450/538...\n",
            "Processing frame 451/538...\n",
            "Processing frame 452/538...\n",
            "Processing frame 453/538...\n",
            "Processing frame 454/538...\n",
            "Processing frame 455/538...\n",
            "Processing frame 456/538...\n",
            "Processing frame 457/538...\n",
            "Processing frame 458/538...\n",
            "Processing frame 459/538...\n",
            "Processing frame 460/538...\n",
            "Processing frame 461/538...\n",
            "Processing frame 462/538...\n",
            "Processing frame 463/538...\n",
            "Processing frame 464/538...\n",
            "Processing frame 465/538...\n",
            "Processing frame 466/538...\n",
            "Processing frame 467/538...\n",
            "Processing frame 468/538...\n",
            "Processing frame 469/538...\n",
            "Processing frame 470/538...\n",
            "Processing frame 471/538...\n",
            "Processing frame 472/538...\n",
            "Processing frame 473/538...\n",
            "Processing frame 474/538...\n",
            "Processing frame 475/538...\n",
            "Processing frame 476/538...\n",
            "Processing frame 477/538...\n",
            "Processing frame 478/538...\n",
            "Processing frame 479/538...\n",
            "Processing frame 480/538...\n",
            "Processing frame 481/538...\n",
            "Processing frame 482/538...\n",
            "Processing frame 483/538...\n",
            "Processing frame 484/538...\n",
            "Processing frame 485/538...\n",
            "Processing frame 486/538...\n",
            "Processing frame 487/538...\n",
            "Processing frame 488/538...\n",
            "Processing frame 489/538...\n",
            "Processing frame 490/538...\n",
            "Processing frame 491/538...\n",
            "Processing frame 492/538...\n",
            "Processing frame 493/538...\n",
            "Processing frame 494/538...\n",
            "Processing frame 495/538...\n",
            "Processing frame 496/538...\n",
            "Processing frame 497/538...\n",
            "Processing frame 498/538...\n",
            "Processing frame 499/538...\n",
            "Processing frame 500/538...\n",
            "Processing frame 501/538...\n",
            "Processing frame 502/538...\n",
            "Processing frame 503/538...\n",
            "Processing frame 504/538...\n",
            "Processing frame 505/538...\n",
            "Processing frame 506/538...\n",
            "Processing frame 507/538...\n",
            "Processing frame 508/538...\n",
            "Processing frame 509/538...\n",
            "Processing frame 510/538...\n",
            "Processing frame 511/538...\n",
            "Processing frame 512/538...\n",
            "Processing frame 513/538...\n",
            "Processing frame 514/538...\n",
            "Processing frame 515/538...\n",
            "Processing frame 516/538...\n",
            "Processing frame 517/538...\n",
            "Processing frame 518/538...\n",
            "Processing frame 519/538...\n",
            "Processing frame 520/538...\n",
            "Processing frame 521/538...\n",
            "Processing frame 522/538...\n",
            "Processing frame 523/538...\n",
            "Processing frame 524/538...\n",
            "Processing frame 525/538...\n",
            "Processing frame 526/538...\n",
            "Processing frame 527/538...\n",
            "Processing frame 528/538...\n",
            "Processing frame 529/538...\n",
            "Processing frame 530/538...\n",
            "Processing frame 531/538...\n",
            "Processing frame 532/538...\n",
            "Processing frame 533/538...\n",
            "Processing frame 534/538...\n",
            "Processing frame 535/538...\n",
            "Processing frame 536/538...\n",
            "Processing frame 537/538...\n",
            "Processing frame 538/538...\n",
            "Reached end of video or failed to read frame.\n",
            "Releasing video resources...\n",
            "\n",
            "Processing complete. Output video saved to: output_video.mp4\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import torch # Optional: for device check\n",
        "\n",
        "# --- Configuration ---\n",
        "\n",
        "# 1. Path to your trained model weights\n",
        "# This should be the 'best.pt' file located in your training results directory\n",
        "# e.g., 'custom_yolo_training/run_auto_yaml_v1/weights/best.pt'\n",
        "# Update this path accordingly!\n",
        "MODEL_PATH = \"/content/custom_yolo_training/run_auto_yaml_v1/weights/best.pt\" # <<< --- UPDATE THIS\n",
        "\n",
        "# 2. Path to the input video file\n",
        "# Update this to the video you want to process\n",
        "INPUT_VIDEO_PATH = \"/content/race.mp4\" # <<< --- UPDATE THIS\n",
        "\n",
        "# 3. Path where the output video will be saved\n",
        "# The script will create this file.\n",
        "OUTPUT_VIDEO_PATH = \"output_video.mp4\" # <<< --- UPDATE THIS (optional)\n",
        "\n",
        "# 4. Inference Parameters (Optional)\n",
        "CONFIDENCE_THRESHOLD = 0.5 # Only show detections with confidence >= 0.5\n",
        "# Set device: 'cuda' for GPU, 'cpu' for CPU, or None for auto-detect\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu' # Or set manually e.g., 'cpu'\n",
        "\n",
        "# --- Check if files exist ---\n",
        "if not os.path.exists(MODEL_PATH):\n",
        "    print(f\"Error: Model weights not found at '{MODEL_PATH}'\")\n",
        "    exit()\n",
        "\n",
        "if not os.path.exists(INPUT_VIDEO_PATH):\n",
        "    print(f\"Error: Input video not found at '{INPUT_VIDEO_PATH}'\")\n",
        "    exit()\n",
        "\n",
        "# --- Load Model ---\n",
        "print(f\"Loading model from: {MODEL_PATH}\")\n",
        "try:\n",
        "    # Load the trained YOLO model\n",
        "    model = YOLO(MODEL_PATH)\n",
        "    # Set device\n",
        "    model.to(DEVICE)\n",
        "    print(f\"Model loaded successfully on device: {DEVICE}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    exit()\n",
        "\n",
        "# --- Open Video File ---\n",
        "print(f\"Opening input video: {INPUT_VIDEO_PATH}\")\n",
        "cap = cv2.VideoCapture(INPUT_VIDEO_PATH)\n",
        "\n",
        "# Check if video opened successfully\n",
        "if not cap.isOpened():\n",
        "    print(f\"Error: Could not open video file {INPUT_VIDEO_PATH}\")\n",
        "    exit()\n",
        "\n",
        "# --- Get Video Properties ---\n",
        "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "print(f\"Video properties: {frame_width}x{frame_height} @ {fps:.2f} FPS, {total_frames} frames\")\n",
        "\n",
        "# --- Define the codec and create VideoWriter object ---\n",
        "# Use 'mp4v' for .mp4 output, or 'XVID' for .avi\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter(OUTPUT_VIDEO_PATH, fourcc, fps, (frame_width, frame_height))\n",
        "\n",
        "print(f\"Output video will be saved to: {OUTPUT_VIDEO_PATH}\")\n",
        "\n",
        "# --- Process Video Frame by Frame ---\n",
        "frame_count = 0\n",
        "while True:\n",
        "    # Read a frame from the video\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    # If frame is not read correctly (end of video), break the loop\n",
        "    if not ret:\n",
        "        print(\"Reached end of video or failed to read frame.\")\n",
        "        break\n",
        "\n",
        "    frame_count += 1\n",
        "    print(f\"Processing frame {frame_count}/{total_frames}...\")\n",
        "\n",
        "    # --- Run YOLO Inference ---\n",
        "    # Perform prediction on the current frame\n",
        "    # 'stream=True' can be more memory efficient for videos but requires handling differently\n",
        "    # Here we process frame by frame, so stream=False is fine.\n",
        "    # 'conf' sets the confidence threshold for detections.\n",
        "    # 'verbose=False' suppresses detailed console output for each frame.\n",
        "    results = model.predict(frame, conf=CONFIDENCE_THRESHOLD, device=DEVICE, verbose=False)\n",
        "\n",
        "    # --- Get Annotated Frame ---\n",
        "    # results[0].plot() returns the frame with bounding boxes/masks drawn on it\n",
        "    # Ensure you are using a recent version of ultralytics for this method\n",
        "    annotated_frame = results[0].plot()\n",
        "\n",
        "    # --- Write Frame to Output Video ---\n",
        "    out.write(annotated_frame)\n",
        "\n",
        "    # --- Display Frame (Optional) ---\n",
        "    # Uncomment the lines below to display the processed frames in a window\n",
        "    # cv2.imshow('YOLO Inference', annotated_frame)\n",
        "    # # Press 'q' to exit the display window early\n",
        "    # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "    #     print(\"Exiting display...\")\n",
        "    #     break\n",
        "\n",
        "# --- Release Resources ---\n",
        "print(\"Releasing video resources...\")\n",
        "cap.release() # Release the input video capture object\n",
        "out.release() # Release the output video writer object\n",
        "cv2.destroyAllWindows() # Close any OpenCV display windows\n",
        "\n",
        "print(f\"\\nProcessing complete. Output video saved to: {OUTPUT_VIDEO_PATH}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyisavxNlaJT",
        "outputId": "e4494197-6d1c-4072-e113-e92c4358a580"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  adding: content/output_annotations/ (stored 0%)\n",
            "  adding: content/output_annotations/frame_00312.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00384.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00060.txt (deflated 78%)\n",
            "  adding: content/output_annotations/frame_00390.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00096.txt (deflated 78%)\n",
            "  adding: content/output_annotations/frame_00408.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00030.txt (deflated 79%)\n",
            "  adding: content/output_annotations/frame_00510.txt (deflated 83%)\n",
            "  adding: content/output_annotations/frame_00204.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00372.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00306.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00072.txt (deflated 79%)\n",
            "  adding: content/output_annotations/frame_00504.txt (deflated 83%)\n",
            "  adding: content/output_annotations/frame_00210.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00294.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00132.txt (deflated 77%)\n",
            "  adding: content/output_annotations/frame_00012.txt (deflated 79%)\n",
            "  adding: content/output_annotations/frame_00018.txt (deflated 79%)\n",
            "  adding: content/output_annotations/frame_00078.txt (deflated 79%)\n",
            "  adding: content/output_annotations/frame_00378.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00534.txt (deflated 81%)\n",
            "  adding: content/output_annotations/frame_00342.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00492.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00462.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00246.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00282.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00468.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00192.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00222.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00180.txt (deflated 76%)\n",
            "  adding: content/output_annotations/frame_00162.txt (deflated 76%)\n",
            "  adding: content/output_annotations/frame_00450.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00102.txt (deflated 77%)\n",
            "  adding: content/output_annotations/frame_00036.txt (deflated 79%)\n",
            "  adding: content/output_annotations/frame_00474.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00420.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00216.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00318.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00336.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00528.txt (deflated 83%)\n",
            "  adding: content/output_annotations/frame_00090.txt (deflated 78%)\n",
            "  adding: content/output_annotations/frame_00084.txt (deflated 78%)\n",
            "  adding: content/output_annotations/frame_00234.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00252.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00114.txt (deflated 77%)\n",
            "  adding: content/output_annotations/frame_00348.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00330.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00108.txt (deflated 76%)\n",
            "  adding: content/output_annotations/frame_00156.txt (deflated 76%)\n",
            "  adding: content/output_annotations/frame_00360.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00264.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00006.txt (deflated 82%)\n",
            "  adding: content/output_annotations/frame_00168.txt (deflated 76%)\n",
            "  adding: content/output_annotations/frame_00270.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00276.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00054.txt (deflated 78%)\n",
            "  adding: content/output_annotations/frame_00444.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00048.txt (deflated 78%)\n",
            "  adding: content/output_annotations/frame_00486.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00258.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00138.txt (deflated 76%)\n",
            "  adding: content/output_annotations/frame_00366.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00042.txt (deflated 77%)\n",
            "  adding: content/output_annotations/frame_00522.txt (deflated 83%)\n",
            "  adding: content/output_annotations/frame_00240.txt (deflated 82%)\n",
            "  adding: content/output_annotations/frame_00432.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00024.txt (deflated 79%)\n",
            "  adding: content/output_annotations/frame_00456.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00426.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00354.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00120.txt (deflated 76%)\n",
            "  adding: content/output_annotations/frame_00186.txt (deflated 82%)\n",
            "  adding: content/output_annotations/frame_00000.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00414.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00402.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00150.txt (deflated 77%)\n",
            "  adding: content/output_annotations/frame_00126.txt (deflated 77%)\n",
            "  adding: content/output_annotations/frame_00288.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00228.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00198.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00144.txt (deflated 76%)\n",
            "  adding: content/output_annotations/frame_00438.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00498.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00174.txt (deflated 77%)\n",
            "  adding: content/output_annotations/frame_00324.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00516.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00066.txt (deflated 78%)\n",
            "  adding: content/output_annotations/frame_00396.txt (deflated 85%)\n",
            "  adding: content/output_annotations/frame_00480.txt (deflated 84%)\n",
            "  adding: content/output_annotations/frame_00300.txt (deflated 84%)\n"
          ]
        }
      ],
      "source": [
        "!zip -r /content/output_annotations.zip /content/output_annotations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "Tzpxf3cTtFbu",
        "outputId": "79e7ddef-c6f0-4570-f241-8110d4fb9ba6"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n    async function download(id, filename, size) {\n      if (!google.colab.kernel.accessAllowed) {\n        return;\n      }\n      const div = document.createElement('div');\n      const label = document.createElement('label');\n      label.textContent = `Downloading \"${filename}\": `;\n      div.appendChild(label);\n      const progress = document.createElement('progress');\n      progress.max = size;\n      div.appendChild(progress);\n      document.body.appendChild(div);\n\n      const buffers = [];\n      let downloaded = 0;\n\n      const channel = await google.colab.kernel.comms.open(id);\n      // Send a message to notify the kernel that we're ready.\n      channel.send({})\n\n      for await (const message of channel.messages) {\n        // Send a message to notify the kernel that we're ready.\n        channel.send({})\n        if (message.buffers) {\n          for (const buffer of message.buffers) {\n            buffers.push(buffer);\n            downloaded += buffer.byteLength;\n            progress.value = downloaded;\n          }\n        }\n      }\n      const blob = new Blob(buffers, {type: 'application/binary'});\n      const a = document.createElement('a');\n      a.href = window.URL.createObjectURL(blob);\n      a.download = filename;\n      div.appendChild(a);\n      a.click();\n      div.remove();\n    }\n  ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": "download(\"download_1e3df51c-57d0-413a-9c4b-ab26c5f79cfa\", \"output_annotations.zip\", 933569)",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/output_annotations.zip\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
