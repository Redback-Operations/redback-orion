{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer\n",
    "from datetime import datetime\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "load_dotenv()\n",
    "# MongoDB Setup\n",
    "# Connect to MongoDB (replace the connection string with your MongoDB credentials)\n",
    "client = MongoClient(os.getenv(\"MONGO_URI\"))  # Local MongoDB connection\n",
    "db = client[os.getenv(\"DB\")]\n",
    "temperature_collection = db[os.getenv(\"COLLECTION\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_occupancy(time):\n",
    "\n",
    "    # Adjust date to the specific time (23:54:48)\n",
    "    \n",
    "    # Convert datetime to string in the required format\n",
    "    query_time_str = time.strftime(\"%Y-%m-%dT%H:%M:%S\")\n",
    "    \n",
    "    # Perform the query using the formatted string\n",
    "    record = temperature_collection.find_one({\"time\": query_time_str})\n",
    "    \n",
    "    if record:\n",
    "        return record.get('Temp', \"No temperature data available\")\n",
    "    else:\n",
    "        print(\"No record found\")\n",
    "        return \"No temperature data available for 2 PM on this date.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/pymongo/ocsp_support.py:284: CryptographyDeprecationWarning: Properties that return a na√Øve datetime object have been deprecated. Please switch to next_update_utc.\n",
      "  if response.next_update and response.next_update < now:\n",
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/pymongo/ocsp_support.py:280: CryptographyDeprecationWarning: Properties that return a na√Øve datetime object have been deprecated. Please switch to this_update_utc.\n",
      "  if response.this_update > now:\n",
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/pymongo/ocsp_cache.py:65: CryptographyDeprecationWarning: Properties that return a na√Øve datetime object have been deprecated. Please switch to next_update_utc.\n",
      "  if value.next_update is None:\n",
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/pymongo/ocsp_cache.py:71: CryptographyDeprecationWarning: Properties that return a na√Øve datetime object have been deprecated. Please switch to this_update_utc.\n",
      "  value.this_update\n",
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/pymongo/ocsp_cache.py:73: CryptographyDeprecationWarning: Properties that return a na√Øve datetime object have been deprecated. Please switch to next_update_utc.\n",
      "  < value.next_update\n",
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/pymongo/ocsp_cache.py:81: CryptographyDeprecationWarning: Properties that return a na√Øve datetime object have been deprecated. Please switch to next_update_utc.\n",
      "  cached_value.next_update is not None\n",
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/pymongo/ocsp_cache.py:82: CryptographyDeprecationWarning: Properties that return a na√Øve datetime object have been deprecated. Please switch to next_update_utc.\n",
      "  and cached_value.next_update < value.next_update\n",
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/pymongo/ocsp_cache.py:98: CryptographyDeprecationWarning: Properties that return a na√Øve datetime object have been deprecated. Please switch to this_update_utc.\n",
      "  assert value.this_update is not None\n",
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/pymongo/ocsp_cache.py:99: CryptographyDeprecationWarning: Properties that return a na√Øve datetime object have been deprecated. Please switch to next_update_utc.\n",
      "  assert value.next_update is not None\n",
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/pymongo/ocsp_cache.py:101: CryptographyDeprecationWarning: Properties that return a na√Øve datetime object have been deprecated. Please switch to this_update_utc.\n",
      "  value.this_update\n",
      "/home/mori/miniconda3/envs/llms/lib/python3.10/site-packages/pymongo/ocsp_cache.py:103: CryptographyDeprecationWarning: Properties that return a na√Øve datetime object have been deprecated. Please switch to next_update_utc.\n",
      "  < value.next_update\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: NVIDIA GeForce RTX 4050 Laptop GPU. Max memory: 5.997 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0. CUDA = 8.9. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.27.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
     ]
    }
   ],
   "source": [
    "# Load a local model (using GPT-2 here, you can replace with a larger model if needed)\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = os.getenv(\"MODEL\"), # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = HF_TOKEN\n",
    "    )\n",
    "FastLanguageModel.for_inference(model) \n",
    "\n",
    "local_llm = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_instruction_response(prompt):\n",
    "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "    outputs = model.generate(input_ids, max_length=128)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_occupancy_with_instruction_model(time):\n",
    "    get_occupancy = get_occupancy(time)\n",
    "    \n",
    "    if get_occupancy != f\"there is no one in the room at {time}\":\n",
    "        # Create a prompt for the instruction model\n",
    "        prompt = f\"What was the occupancy on {time.strftime('%Y-%m-%d')}?\"\n",
    "        # Generate a response using the instruction-tuned model\n",
    "        response = generate_instruction_response(prompt + f\" The temperature was {temperature}¬∞C.\")\n",
    "        return response\n",
    "    else:\n",
    "        return get_occupancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What was the temperature at 2 PM on 2020-12-19? The temperature was 15.4¬∞C. What was the temperature at 2 PM on 2020-12-20? The temperature was 14.8¬∞C. What was the temperature at 2 PM on 2020-12-21? The temperature was 15.1¬∞C. What was the temperature at 2 PM on 2020-12-22? The temperature was 14.5¬∞C.\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "date = datetime(2020, 12, 19,23,29)  # Replace with the desired date\n",
    "result = query_occupancy_with_instruction_model(date)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
